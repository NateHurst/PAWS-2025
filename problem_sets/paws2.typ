// Example usage of the homework template
#import "homework-template.typ": *

// Page setup (MUST be at document level, not in function)
#set page(
  margin: (left: 1in, right: 1in),
  numbering: "1",
  footer: [
    #align(center)[#context [#counter(page).display()]]
  ],
)
#set par(first-line-indent: 0pt)
#set block(spacing: 2.5em)

// Create the homework title
#homework_title("Problem Set 2", "PAWS 2025", "Nathaniel Hurst")


// Numbered problems with yellow boxes and circled numbers
#numbered_problem(1)[
    The order of $2$ in $FF_(71)^*$ is $35$. Charlie uses the subgroup generated by $g = 2$, his public key is $g_c = 29$. Use the baby-step giant-step algorithm to compute an integer $c$ such that $g_c equiv g^c space (mod 71)$.
 
]

a

#numbered_problem(2)[

We have seen in Remark 2.12 (of the lecture notes) that one may reduce the size of the required memory at the cost of increasing the overall runtime of the algorithm. In this exercise, the goal is to achieve the opposite: decreasing the runtime at the cost of increasing the required memory.

(a) We have shown that Algorithm 1 (of the lecture notes) requires $O(sqrt(q))$ multiplications. More concretely, show that the average runtime is given by $T = 4 / 2 sqrt(q)$ (if the exponent $a$ is chosen uniformly at random).
        
Now consider a variant of Algorithm 1, where the baby steps and giant steps are computed in parallel, and all values $g_i, A_i$ for $0 <= i <= n <= m$ are stored until the match is found for some $n$.
        
(b) What is the average runtime of this variant of Algorithm 1? What is the required memory? 
        
*Hint:* You can use (or prove if you are familiar with probability theory) that for two integers $i, j$ uniformly chosen at random from $(0, dots, m)$, the expected value of $max(i,j) approx 2/3m$.
        
]

a

#numbered_problem(3)[

Implement the baby-step giant-step algorithm and use it to solve the DLP instances from Exercise 5 of the first exercise set (copied again here). How does the running time compare to the $log$ function in SageMath? Which algorithm is used in SageMath to solve the DLP?

    In all of these, the public parameters are a prime $p = 2q + 1$, and the element $g = 4 in FF_p^*$ with order $q$:
    
(a) $q = 4294967681 approx 2^(32)$, 
        $A = 5104411285$, $B = 7620748646$.
        
(b) $q = 18446744073709552109 approx 2^(64)$, 
        $A = 17485644247020728566$, $B = 17485644247020728566$.
        
(c) $q = 340282366920938463463374607431768219863 approx 2^(128)$, 
        $A = 15855669586157245378211095347605706305$, 
        $B = 643791185530305885858740134946520672205$

]

a

#numbered_problem(4)[
Use Pollard's rho algorithm to compute $c$ such that $2^c equiv 29 space (mod 71)$, i.e., use Pollard's rho algorithm to do Exercise 1 in this Problem Set. What are $T$ and $L$? How does the value of $T + L$ compare to the expected value given in Theorem 2.16?
]

a

#numbered_problem(5)[
Explain why $f(x) = x^2$ is a bad (inefficient) choice of function for Pollard’s rho algorithm (say, with initial value $x_0 = g dot A$, where the order of $g$ is odd).
]

a

#numbered_problem(6)[
*Pollard’s $rho$ for Integer Factorization*. You already know that Pollard’s $rho$ algorithm can be used to solve the *discrete logarithm problem* by exploiting cycle detections. The same idea can be adapted to *factor composite integers*, i.e. find prime numbers $p_1, dots, p_r$ such that $n = p_1 dots p_r$.

Let $n$ be a composite integer. Consider the sequence
#align(center, $x_(k+1) equiv pi(x_k) := x^2 + 1 space (mod n)$)

Because there are only $n$ residues, the sequence eventually repeats. If a prime $p | n$ causes two values to collide modulo $p$ before they collide modulo $n$, then
#align(center, $gcd(|x_i - x_j|, n)$)
   
can reveal a non-trivial factor of $n$.

(a) Show that if $x_i equiv x_j space (mod p)$, then $x_(i+k) equiv x_(j+k) space (mod p)$ for all $k >= 0$.

(b) Implement Pollard’s $rho$ method of factorization in Sagemath and use it to factor the following integers:
        
#align(center, $n_1 &= 1007 
            n_2 &= 8051 
            n_3 &= 10403
            n_4 &= 5545419598547562675200 
            n_5 &= 62636019807439769674752
            n_6 &= 19783
            n_7 &= 16310011$)

        (Yes, they are ordered from easy to hard :), do the next one if you want to understand why)

(c) Use Theorem 2.16 to estimate the expected number of steps needed to factor $n$, assuming $pi$ to be a random permutation. Note: it may be helpful to use the Theorem on a function different from $pi$, since you are looking for a collision modulo one of the prime factors of $n$.

(d) Explain why Pollard’s $rho$ is particularly effective when $n$ has many small prime factors, even if $n$ itself is large.

]

a

#numbered_problem(7)[
Implement the Pollard rho algorithm in Sagemath and use it solve the DLP instances from Exercise 3. Compare the run times with your baby-step giant-step implementation.
]

a

#numbered_problem(8)[
Use index calculus to compute an integer $c$ such that $2^c equiv 29 space (mod 71)$ (i.e., use index calculus to solve #1 on this problem set). Use factor base $cal(P)_B = {2, 3, 5}$ and the sequence of integers $e = 5, 13, 32, 19$.

]

a

#numbered_problem(9)[
When looking at Example 2.19 from the lecture notes, can you also solve for $x_2$, $x_3$ and $x_5$? Explain your observations.

]

a

#numbered_problem(10)[
Try to implement the Index Calculus algorithm (Algorithm 3 from the notes) in Sagemath. Here are some hints:

    (i) *list(primes(B))* gives you a list of all primes up to $B$;
    
    (ii) You can initialize the matrix to then the relations having $b$ columns and $b+1$ rows;
    
    (iii) You do not need to factor completely, just divide out the primes in your factor base, then if you get 1 it means the number was completely factored;
    
    (iv) You can use *A.solve_right(b)* to solve the linear system $A x = b$ in $FF_q$.
]

a

#numbered_problem(11)[
Let $T_B$ be the expected number of trials of random integers modulo $p$ until one is $B$-smooth, $b$ be the number of primes up to $B$, $r$ is the (prime) order of $g$ and $M(t)$ be the number of bit operations required to multiply two $t$-bit integers. 

Then, the expected running time of the Index Calculus algorithm (using naive trial division and specialized methods for the *sparse* linear system) is:
#align(center, $O(b^2 T_B M(log(p)) + b^(2+o(1))M(log(r))) "for" p -> infinity$)


Let $L_p(c,1/2)$ be the subexponential function defined as
#align(center, $L_p(c,1/2) = e^(c sqrt(log(p) log(log(p))))$)


Assuming that $B = L_p(c,1/2)$ for some constant $c > 0$ and $T_B = L_p(1/2,1/(2c) + o(1))$, show that the optimal value for $c$ is $1/2$. Then estimate the asymptotic complexity of the Index Calculus algorithm.
]

a

#numbered_problem(12)[
Use your implementation of the Index Calculus algorithm to run some experiments and find an optimal value for $B$ for 
#align(center, $p = 2 dot 386545163 + 1, space space space g = 4$)

Does your experimental optimal value for $B$ agree with the asymptotic value you found in the previous exercise? How does it change? Try to use larger primes and find the optimal $B = L_p(1/2,c)$ for your implementation experimentally.

]

a